ğŸ›¡ï¸ PhishGuard AI â€” Phishing Website Detection System

PhishGuard AI is a complete, end-to-end phishing website detection system designed for academic evaluation, hackathons, and real-world demonstration.

The system combines Machine Learning, Explainable AI (XAI), a secure Flask backend, a modern web interface, and a browser extension to detect phishing websites with clarity and confidence.

ğŸš¨ Problem Statement

Phishing websites imitate trusted platforms to steal:

Login credentials

Banking and financial details

Personal and sensitive information

Due to increasingly sophisticated URL structures, most users cannot reliably distinguish phishing websites from legitimate ones.

Even one false negative (missing a phishing site) can lead to serious damage.

âœ… Solution Overview

PhishGuard AI addresses this problem by providing:

Machine-learning-based phishing detection

Security-first decision logic (high recall)

Human-readable explanations for every prediction

Multiple interfaces:

Web application

Browser extension (real-world usage)

ğŸ§  System Architecture
User (Browser / Extension)
        â†“
Frontend / Browser Extension
        â†“  REST API
Flask Backend
        â†“
ML Model (Scikit-learn)

End-to-End Flow

User provides or visits a website URL

URL is sent to the Flask backend

URL features are extracted

ML model predicts phishing probability

Explainable risk factors are generated

Result is returned with confidence and risk level

âœ¨ Core Features (Phase-Wise)
ğŸ”¹ Phase 1 â€” Feature Engineering

Security-oriented URL features were introduced to improve detection accuracy.

Features used:

URL length

Number of dots (subdomains)

Presence of @ symbol

Presence of hyphens (-)

IP address instead of domain

HTTPS usage

Phishing-related keywords

Digit count

Special character count

Subdomain depth

Binary suspicious keyword indicator

âœ” Improves pattern recognition
âœ” Backward-compatible
âœ” Deterministic feature extraction

ğŸ”¹ Phase 2 â€” Dataset & Model Intelligence

This phase focused on model reliability and academic strength.

Enhancements:

Dataset cleaning (duplicates, invalid entries removed)

Dataset balancing to avoid class bias

Multi-model training:

Logistic Regression

Random Forest

Gradient Boosting

Evaluation using:

Accuracy

Precision

Recall

F1-Score

Automatic best-model selection based on F1-Score

âœ” Scientifically justified model choice
âœ” Security-oriented evaluation

ğŸ”¹ Phase 3 â€” Explainable AI, Backend & UX

This phase transformed the model into a usable security system.

Key features:

Explainable AI (why a URL is risky)

Confidence-based classification:

SAFE

SUSPICIOUS

PHISHING

Risk levels:

Low

Medium

High

Scan history logging (scan_history.csv)

Secure Flask backend with:

Input validation

Health-check endpoint

Error handling

CORS support

Improved frontend UX:

Loading indicators

Disabled buttons during scans

Keyboard support

Clear visual status indicators

âœ” Transparent
âœ” User-friendly
âœ” Demo-ready

ğŸ”¹ Phase 4 â€” Browser Extension (Real-World Deployment)

Phase 4 introduced real-world usability through a browser extension.

Browser Extension Capabilities:

Automatically reads the current website URL

One-click phishing scan

Displays:

Classification

Confidence score

Risk level

Explainable risk factors

Uses the same backend and ML model

No ML logic inside the extension

New files added:

extension/
â”œâ”€â”€ manifest.json
â”œâ”€â”€ popup.html
â”œâ”€â”€ popup.js
â””â”€â”€ style.css


âœ” No retraining required
âœ” Existing web app remains unchanged
âœ” Clean separation of concerns

ğŸ¤– Machine Learning Details

Algorithm: Random Forest Classifier

Library: Scikit-learn

Probability-based predictions (predict_proba)

Recall prioritized over accuracy

In cybersecurity, missing an attack is worse than raising a warning.

ğŸ§  Explainable AI (XAI)

For every scan, the system explains why a URL is risky.

Example explanations:

URL is unusually long

Multiple subdomains detected

Suspicious keyword found

Website does not use HTTPS

IP address used instead of domain

âœ” Builds trust
âœ” Easy to defend during evaluation

ğŸ“Š Logging & Monitoring

All scans are logged in:

logs/scan_history.csv


Logged data includes:

Timestamp

URL

Prediction label

Confidence

Risk level

âš ï¸ Logs are not used for automatic training.
They are intended for auditing, analysis, and future controlled improvement.

ğŸ“ Project Structure
phishing_detection_system/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ script.js
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ train_model.py
â”‚   â””â”€â”€ features.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_urls.csv
â”œâ”€â”€ extension/
â”‚   â”œâ”€â”€ manifest.json
â”‚   â”œâ”€â”€ popup.html
â”‚   â”œâ”€â”€ popup.js
â”‚   â””â”€â”€ style.css
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ scan_history.csv
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ Setup & Execution
1ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

2ï¸âƒ£ Train the Model
python ai/train_model.py

3ï¸âƒ£ Run Backend
python backend/app.py


Backend runs at:

http://127.0.0.1:5000

4ï¸âƒ£ Run Web App

Open:

frontend/index.html

5ï¸âƒ£ Load Browser Extension

Open chrome://extensions/

Enable Developer Mode

Click Load unpacked

Select the extension/ folder